{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pill 18 WIKI Side Quest: Manifold learning and autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### by Toni Miranda, based on *Chapter 8 - Generative Deep Learning*, of \"Deep Learning for Python by François Chollet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful tricks for GAN implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANs are difficult to train, because training a GAN is a dynamic process rather than a simple gradient descent process with a fixed loss landscape. Getting a GAN to train correctly requires using a number of heuristic tricks, as well as extensive tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A schematic GAN implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly revisit a GAN implementation adding on top of what has been said by classmates in the Subquest task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A generator network maps vectors to images.\n",
    "2. A discriminator network maps images to a binary score estimating the probability that the image is real.\n",
    "3. A GAN network chains the generator and the discriminator together: gan(x) = discriminator(generator(x)). Thus this GAN network maps latent space vectors to the discriminator’s assessment of the realism of these latent vectors as decoded by the generator.\n",
    "4. You train the discriminator using examples of real and fake images along with “real”/“fake” labels, just as you train any regular image-classification model.\n",
    "5. To train the generator, you use the gradients of the generator’s weights with regard to the loss of the gan model. This means, at every step, you move the weights of the generator in a direction that makes the discriminator more likely to classify as “real” the images decoded by the generator. In other words, you train the generator to fool the discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, GANs are difficult to train, here Chollet gives some (non exhaustive) list of tricks used in implementation of the GAN generator and discriminator:\n",
    "- Use of $tanh$ as the last activation in the generator, instead of $sigmoid$, which is more commonly found in other types of models.\n",
    "- We sample points from the latent space using a normal distribution (Gaussian distribution), not a uniform distribution.\n",
    "- Stochasticity is good to induce robustness. Because GAN training results in a dynamic equilibrium, GANs are likely to get stuck in all sorts of ways. Introducing randomness during training helps prevent this. Randomness can be introduced in two ways: by using dropout in the discriminator and by adding random noise to the labels for the discriminator.\n",
    "- Sparse gradients can make GAN training difficult. In deep learning, sparsity is often a desirable property, but not in GANs. Two things can induce gradient sparsity: max pooling operations (aggressively downsample feature maps) and ReLU activations (relu(x) is max(x, 0)). Instead of max pooling, it is recommended using strided convolutions (not continuous convolution windows) for downsampling, and also using a variation of the ReLu that relaxes sparsity constraints by allowing small negative activation values (LeakyReLU).\n",
    "- In generated images, it’s common to see checkerboard artifacts caused by unequal coverage of the pixel space in the generator (see *Fig 1* below). To fix this, it is recommended to use a kernel size that’s divisible by the stride size whenever strided conv is used in both the generator and the discriminator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./checkboard_artifacts.png)\n",
    "*Fig 1.* Checkerboard artifacts caused by mismatching strides and kernel sizes, resulting in unequal pixel-space coverage: one of the many gotchas of GANs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
