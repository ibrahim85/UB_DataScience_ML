{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pill 19b WIKI Side Quest: ECOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code and explore the problem of Error Correcting Output Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### by Toni Miranda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to expand on what has been said by classmates on ECOCs by presenting a particular application of ECOCs for text classification based on Adam Berger from Carnegie Mellon University paper (\"Error-Correcting Output Coding for Text Classification\"), and secondly, by pointing out an ECOCs library developed by our professor, Dr. Oriol Pujol, among others (\"Error-Correcting Ouput Codes Library\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error-Correcting Output Coding for Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on: Adam Berger from Carnegie Mellon University paper \"Error-Correcting Output Coding for Text Classification\"\n",
    "\n",
    "This paper applies ECOC to the task of document categorization. As presented by other classmates, ECOC is a method for decomposing a multiway classification problem into many binary classification tasks, and then combining the results of the subtasks into a hypothesized solution to the original problem. In this paper, author provides experimental results on several datasets, which demonstrate that ECOC can offer significant improvements in accuracy over conventional classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Training algorithm*\n",
    "\n",
    "Training an ECOC classifier consists of learning a set Λ = {λ1, λ2 . . . λn} of independent binary classifiers. With Λ in hand, one can hypothesize the correct class of an unlabeled document x as follows. Evaluate each independent classifier on x, generating a n-bit vector Λ(x) = {λ1(x), λ2(x), . . . λn(x)}. Most likely, the generated bitvector Λ(x) will not be a row of C, but it will certainly be closer (in Hamming distance ∆, say) to some rows than to others. \n",
    "\n",
    "Here is the algorithm in pseudo-code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./Training_ECOC.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Applying an ECOC document classifier*\n",
    "\n",
    "Categorizing the document $x$ involves selecting argmini ∆(C_{i}, Λ(x)), the label i for which Ci is closest to Λ(x). (If more than one row of C are equidistant to Λ(x), select one arbitrarily.) For in- stance, if the generated bitvector Λ(x) = {1010111101}, the document would receive the label *business*, for example.\n",
    "\n",
    "In general, λj(x) may not be a 0/1 value, but a real-valued probability, measuring the classifier’s confidence that document x belongs in the j’th superclass. Here is the algorithm in pseudo-code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./ECOC_Applying_algorithm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper: http://www.cs.cmu.edu/~aberger/pdf/ecoc.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error-Correcting Ouput Codes Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This library contains both state-of-the-art (as of 2010) coding (one-versus-one, one-versus-all, dense random, sparse random, DECOC, forest-ECOC, and ECOC-ONE) and decoding designs (hamming, euclidean, inverse hamming, laplacian, β-density, attenuated, loss-based, probabilistic kernel-based, and loss- weighted) with the parameters defined by the authors, as well as the option to include your own coding, decoding, and base classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the code is in Matlab/Octave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper: http://www.jmlr.org/papers/volume11/escalera10a/escalera10a.pdf\n",
    "\n",
    "Library on github: https://github.com/bkong/ecoclib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
